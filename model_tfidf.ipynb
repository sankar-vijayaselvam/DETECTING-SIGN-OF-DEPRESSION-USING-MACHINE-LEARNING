{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a55c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda1e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('preprocessed_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc28adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Text data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_pid_1</td>\n",
       "      <td>waiting mind breakdown new year feeling isnt a...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_pid_2</td>\n",
       "      <td>new years resolution im gon na get ass therapi...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_pid_3</td>\n",
       "      <td>new year somone else feeling like 2020 last ye...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_pid_4</td>\n",
       "      <td>story guess hi im germany english mostly self ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_pid_5</td>\n",
       "      <td>sat dark cried going new year great start 2020</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11029</th>\n",
       "      <td>train_pid_5033</td>\n",
       "      <td>never want rely anyone lowkey always probably</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030</th>\n",
       "      <td>train_pid_5051</td>\n",
       "      <td>anyone else feel like every single week dumb s...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11031</th>\n",
       "      <td>train_pid_1722</td>\n",
       "      <td>well well im done cant believe im saying ive f...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11032</th>\n",
       "      <td>train_pid_5373</td>\n",
       "      <td>thinking maxing two credit cards buy gaming la...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11033</th>\n",
       "      <td>train_pid_5796</td>\n",
       "      <td>ive taking consistent showers last 2 weeks im ...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11034 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  PID                                          Text data  \\\n",
       "0         train_pid_1  waiting mind breakdown new year feeling isnt a...   \n",
       "1         train_pid_2  new years resolution im gon na get ass therapi...   \n",
       "2         train_pid_3  new year somone else feeling like 2020 last ye...   \n",
       "3         train_pid_4  story guess hi im germany english mostly self ...   \n",
       "4         train_pid_5     sat dark cried going new year great start 2020   \n",
       "...               ...                                                ...   \n",
       "11029  train_pid_5033      never want rely anyone lowkey always probably   \n",
       "11030  train_pid_5051  anyone else feel like every single week dumb s...   \n",
       "11031  train_pid_1722  well well im done cant believe im saying ive f...   \n",
       "11032  train_pid_5373  thinking maxing two credit cards buy gaming la...   \n",
       "11033  train_pid_5796  ive taking consistent showers last 2 weeks im ...   \n",
       "\n",
       "                Label  \n",
       "0            moderate  \n",
       "1            moderate  \n",
       "2            moderate  \n",
       "3            moderate  \n",
       "4            moderate  \n",
       "...               ...  \n",
       "11029  not depression  \n",
       "11030  not depression  \n",
       "11031  not depression  \n",
       "11032  not depression  \n",
       "11033  not depression  \n",
       "\n",
       "[11034 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8b7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7ba892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "x = data['Text data']\n",
    "y = data['Label']\n",
    "x = np.array(data.iloc[:,0].values)\n",
    "y = np.array(data['Label'].values)\n",
    "w2v = TfidfVectorizer()\n",
    "x = w2v.fit_transform(data['Text data']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c3b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f904578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ebaee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca027cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['severe', 'severe', 'severe', ..., 'not depression',\n",
       "       'not depression', 'moderate'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63433f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['moderate', 'moderate', 'not depression', ..., 'not depression',\n",
       "       'not depression', 'severe'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea9fb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Logistic Regression: % 73.24\n",
      "Confusion Matrix\n",
      "[[ 603  317  138]\n",
      " [ 254  819   64]\n",
      " [  77   36 1003]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.65      0.57      0.61      1058\n",
      "not depression       0.70      0.72      0.71      1137\n",
      "        severe       0.83      0.90      0.86      1116\n",
      "\n",
      "      accuracy                           0.73      3311\n",
      "     macro avg       0.73      0.73      0.73      3311\n",
      "  weighted avg       0.73      0.73      0.73      3311\n",
      "\n",
      "Precision : 0.732407127755965\n",
      "Recall : 0.732407127755965\n",
      "F1-score : 0.732407127755965\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "oneVsRestlr = OneVsRestClassifier(lr)\n",
    "oneVsRestlr.fit(x_train, y_train)\n",
    "y_pred = oneVsRestlr.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Logistic Regression: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d15e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Gaussian Naive Bayes: % 60.86\n",
      "Confusion Matrix\n",
      "[[ 384  132  542]\n",
      " [ 121  529  487]\n",
      " [  10    4 1102]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.75      0.36      0.49      1058\n",
      "not depression       0.80      0.47      0.59      1137\n",
      "        severe       0.52      0.99      0.68      1116\n",
      "\n",
      "      accuracy                           0.61      3311\n",
      "     macro avg       0.69      0.61      0.58      3311\n",
      "  weighted avg       0.69      0.61      0.59      3311\n",
      "\n",
      "Precision : 0.6085774690425854\n",
      "Recall : 0.6085774690425854\n",
      "F1-score : 0.6085774690425854\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "oneVsRestgnb = OneVsRestClassifier(gnb)\n",
    "oneVsRestgnb.fit(x_train, y_train)\n",
    "y_pred = oneVsRestgnb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Gaussian Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e64aa018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Random Forest: % 84.23\n",
      "Confusion Matrix\n",
      "[[ 795  239   24]\n",
      " [ 223  904   10]\n",
      " [  22    4 1090]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.76      0.75      0.76      1058\n",
      "not depression       0.79      0.80      0.79      1137\n",
      "        severe       0.97      0.98      0.97      1116\n",
      "\n",
      "      accuracy                           0.84      3311\n",
      "     macro avg       0.84      0.84      0.84      3311\n",
      "  weighted avg       0.84      0.84      0.84      3311\n",
      "\n",
      "Precision : 0.8423437028088191\n",
      "Recall : 0.8423437028088191\n",
      "F1-score : 0.8423437028088191\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0)\n",
    "oneVsRestrf = OneVsRestClassifier(rf)\n",
    "oneVsRestrf.fit(x_train, y_train)\n",
    "y_pred = oneVsRestrf.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Random Forest: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7f2ec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Multinomial Naive Bayes: % 64.94\n",
      "Confusion Matrix\n",
      "[[ 704   85  269]\n",
      " [ 500  429  208]\n",
      " [  91    8 1017]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.54      0.67      0.60      1058\n",
      "not depression       0.82      0.38      0.52      1137\n",
      "        severe       0.68      0.91      0.78      1116\n",
      "\n",
      "      accuracy                           0.65      3311\n",
      "     macro avg       0.68      0.65      0.63      3311\n",
      "  weighted avg       0.69      0.65      0.63      3311\n",
      "\n",
      "Precision : 0.6493506493506493\n",
      "Recall : 0.6493506493506493\n",
      "F1-score : 0.6493506493506493\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1.0,fit_prior=True)\n",
    "oneVsRestmnb = OneVsRestClassifier(mnb)\n",
    "oneVsRestmnb.fit(x_train, y_train)\n",
    "y_pred = oneVsRestmnb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Multinomial Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fcc36a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Decision Tree: % 71.16\n",
      "Confusion Matrix\n",
      "[[ 348  305  405]\n",
      " [  94  908  135]\n",
      " [  13    3 1100]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.76      0.33      0.46      1058\n",
      "not depression       0.75      0.80      0.77      1137\n",
      "        severe       0.67      0.99      0.80      1116\n",
      "\n",
      "      accuracy                           0.71      3311\n",
      "     macro avg       0.73      0.70      0.68      3311\n",
      "  weighted avg       0.73      0.71      0.68      3311\n",
      "\n",
      "Precision : 0.7115675022651767\n",
      "Recall : 0.7115675022651767\n",
      "F1-score : 0.7115675022651767\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "oneVsRestdt = OneVsRestClassifier(dt)\n",
    "oneVsRestdt.fit(x_train, y_train)\n",
    "y_pred = oneVsRestdt.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Decision Tree: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60786e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10 , metric= 'minkowski' , p = 4)\n",
    "oneVsRestknn = OneVsRestClassifier(knn)\n",
    "oneVsRestknn.fit(x_train, y_train)\n",
    "y_pred = oneVsRestknn.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic K Nearest Neighbor: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d783536",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('preprocessed_dev_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['text data']\n",
    "y = data['Class labels']\n",
    "x = np.array(data.iloc[:,0].values)\n",
    "y = np.array(data['Class labels'].values)\n",
    "w2v = TfidfVectorizer()\n",
    "x = w2v.fit_transform(data['Text data']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f3469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "124aaaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e7eff31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ed34f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14017279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88e0e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Logistic Regression: % 73.24\n",
      "Confusion Matrix\n",
      "[[ 603  138  317]\n",
      " [  77 1003   36]\n",
      " [ 254   64  819]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61      1058\n",
      "           1       0.83      0.90      0.86      1116\n",
      "           2       0.70      0.72      0.71      1137\n",
      "\n",
      "    accuracy                           0.73      3311\n",
      "   macro avg       0.73      0.73      0.73      3311\n",
      "weighted avg       0.73      0.73      0.73      3311\n",
      "\n",
      "Precision : 0.732407127755965\n",
      "Recall : 0.732407127755965\n",
      "F1-score : 0.732407127755965\n"
     ]
    }
   ],
   "source": [
    "oneVsRestlr.fit(x_train, y_train)\n",
    "y_pred = oneVsRestlr.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Logistic Regression: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e4db30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Gaussian Naive Bayes: % 70.28\n",
      "Confusion Matrix\n",
      "[[384 122 552]\n",
      " [ 10 966 140]\n",
      " [121  39 977]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.36      0.49      1058\n",
      "           1       0.86      0.87      0.86      1116\n",
      "           2       0.59      0.86      0.70      1137\n",
      "\n",
      "    accuracy                           0.70      3311\n",
      "   macro avg       0.73      0.70      0.68      3311\n",
      "weighted avg       0.73      0.70      0.69      3311\n",
      "\n",
      "Precision : 0.7028088190878888\n",
      "Recall : 0.7028088190878888\n",
      "F1-score : 0.7028088190878888\n"
     ]
    }
   ],
   "source": [
    "oneVsRestgnb.fit(x_train, y_train)\n",
    "y_pred = oneVsRestgnb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Gaussian Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c08cc2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Random Forest: % 84.23\n",
      "Confusion Matrix\n",
      "[[ 795   24  239]\n",
      " [  22 1090    4]\n",
      " [ 223   10  904]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1058\n",
      "           1       0.97      0.98      0.97      1116\n",
      "           2       0.79      0.80      0.79      1137\n",
      "\n",
      "    accuracy                           0.84      3311\n",
      "   macro avg       0.84      0.84      0.84      3311\n",
      "weighted avg       0.84      0.84      0.84      3311\n",
      "\n",
      "Precision : 0.8423437028088191\n",
      "Recall : 0.8423437028088191\n",
      "F1-score : 0.8423437028088191\n"
     ]
    }
   ],
   "source": [
    "oneVsRestrf.fit(x_train, y_train)\n",
    "y_pred = oneVsRestrf.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Random Forest: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c48973f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Multinomial Naive Bayes: % 64.94\n",
      "Confusion Matrix\n",
      "[[ 704  269   85]\n",
      " [  91 1017    8]\n",
      " [ 500  208  429]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60      1058\n",
      "           1       0.68      0.91      0.78      1116\n",
      "           2       0.82      0.38      0.52      1137\n",
      "\n",
      "    accuracy                           0.65      3311\n",
      "   macro avg       0.68      0.65      0.63      3311\n",
      "weighted avg       0.69      0.65      0.63      3311\n",
      "\n",
      "Precision : 0.6493506493506493\n",
      "Recall : 0.6493506493506493\n",
      "F1-score : 0.6493506493506493\n"
     ]
    }
   ],
   "source": [
    "oneVsRestmnb.fit(x_train, y_train)\n",
    "y_pred = oneVsRestmnb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Multinomial Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneVsRestdt.fit(x_train, y_train)\n",
    "y_pred = oneVsRestdt.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Decision Tree: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneVsRestknn.fit(x_train, y_train)\n",
    "y_pred = oneVsRestknn.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic K Nearest Neighbor: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
