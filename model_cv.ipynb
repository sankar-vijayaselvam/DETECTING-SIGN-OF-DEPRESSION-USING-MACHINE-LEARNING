{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a55c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda1e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('preprocessed_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc28adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pid</th>\n",
       "      <th>text data</th>\n",
       "      <th>Class labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_pid_1</td>\n",
       "      <td>im scared lie every day say ill make think mig...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_pid_2</td>\n",
       "      <td>new wanted vent finally realized im kind bad m...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_pid_3</td>\n",
       "      <td>im sad kinda always issue wouldnt say bad peer...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_pid_4</td>\n",
       "      <td>lonely alone immediately family members dead d...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_pid_5</td>\n",
       "      <td>year trash dont know im posting dont even know...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>dev_pid_2514</td>\n",
       "      <td>anyone feared theyll kill loved ones sleep uni...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>dev_pid_2829</td>\n",
       "      <td>finally got fulltime job feel even worse maybe...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>dev_pid_2260</td>\n",
       "      <td>deal boredomnothing satisfying anymore days ta...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>dev_pid_2653</td>\n",
       "      <td>got bed showered morning removed</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>dev_pid_2460</td>\n",
       "      <td>depressed suicidal 2018 start 2020 ive woken d...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6507 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pid                                          text data  \\\n",
       "0        dev_pid_1  im scared lie every day say ill make think mig...   \n",
       "1        dev_pid_2  new wanted vent finally realized im kind bad m...   \n",
       "2        dev_pid_3  im sad kinda always issue wouldnt say bad peer...   \n",
       "3        dev_pid_4  lonely alone immediately family members dead d...   \n",
       "4        dev_pid_5  year trash dont know im posting dont even know...   \n",
       "...            ...                                                ...   \n",
       "6502  dev_pid_2514  anyone feared theyll kill loved ones sleep uni...   \n",
       "6503  dev_pid_2829  finally got fulltime job feel even worse maybe...   \n",
       "6504  dev_pid_2260  deal boredomnothing satisfying anymore days ta...   \n",
       "6505  dev_pid_2653                   got bed showered morning removed   \n",
       "6506  dev_pid_2460  depressed suicidal 2018 start 2020 ive woken d...   \n",
       "\n",
       "        Class labels  \n",
       "0           moderate  \n",
       "1           moderate  \n",
       "2           moderate  \n",
       "3           moderate  \n",
       "4           moderate  \n",
       "...              ...  \n",
       "6502  not depression  \n",
       "6503  not depression  \n",
       "6504  not depression  \n",
       "6505  not depression  \n",
       "6506  not depression  \n",
       "\n",
       "[6507 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7eaa947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pid</th>\n",
       "      <th>text data</th>\n",
       "      <th>Class labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_pid_1</td>\n",
       "      <td>im scared lie every day say ill make think mig...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_pid_2</td>\n",
       "      <td>new wanted vent finally realized im kind bad m...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_pid_3</td>\n",
       "      <td>im sad kinda always issue wouldnt say bad peer...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_pid_4</td>\n",
       "      <td>lonely alone immediately family members dead d...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_pid_5</td>\n",
       "      <td>year trash dont know im posting dont even know...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pid                                          text data Class labels\n",
       "0  dev_pid_1  im scared lie every day say ill make think mig...     moderate\n",
       "1  dev_pid_2  new wanted vent finally realized im kind bad m...     moderate\n",
       "2  dev_pid_3  im sad kinda always issue wouldnt say bad peer...     moderate\n",
       "3  dev_pid_4  lonely alone immediately family members dead d...     moderate\n",
       "4  dev_pid_5  year trash dont know im posting dont even know...     moderate"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7ba892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "x = data['Text data']\n",
    "y = data['Label']\n",
    "x = np.array(data.iloc[:,0].values)\n",
    "y = np.array(data['Label'].values)\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(data['Text data']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c3b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f904578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ebaee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca027cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not depression', 'severe', 'moderate', ..., 'moderate', 'severe',\n",
       "       'severe'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63433f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['moderate', 'severe', 'moderate', ..., 'severe', 'not depression',\n",
       "       'not depression'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a8f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc255f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VASANTHARAN 21ADR056\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\VASANTHARAN 21ADR056\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\VASANTHARAN 21ADR056\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Logistic Regression: % 86.33\n",
      "Confusion Matrix\n",
      "[[426 175  42]\n",
      " [ 48 595   2]\n",
      " [  0   0 665]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.90      0.66      0.76       643\n",
      "not depression       0.77      0.92      0.84       645\n",
      "        severe       0.94      1.00      0.97       665\n",
      "\n",
      "      accuracy                           0.86      1953\n",
      "     macro avg       0.87      0.86      0.86      1953\n",
      "  weighted avg       0.87      0.86      0.86      1953\n",
      "\n",
      "Precision : 0.8632872503840245\n",
      "Recall : 0.8632872503840245\n",
      "F1-score : 0.8632872503840245\n"
     ]
    }
   ],
   "source": [
    "mdl = LogisticRegression()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Logistic Regression: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436dfaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Gaussian Naive Bayes: % 72.3\n",
      "Confusion Matrix\n",
      "[[272 133 238]\n",
      " [ 44 475 126]\n",
      " [  0   0 665]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.86      0.42      0.57       643\n",
      "not depression       0.78      0.74      0.76       645\n",
      "        severe       0.65      1.00      0.79       665\n",
      "\n",
      "      accuracy                           0.72      1953\n",
      "     macro avg       0.76      0.72      0.70      1953\n",
      "  weighted avg       0.76      0.72      0.70      1953\n",
      "\n",
      "Precision : 0.7229902713773682\n",
      "Recall : 0.7229902713773682\n",
      "F1-score : 0.722990271377368\n"
     ]
    }
   ],
   "source": [
    "mdl = GaussianNB()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Gaussian Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0)\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Random Forest: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23d586a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Multinomial Naive Bayes: % 81.82\n",
      "Confusion Matrix\n",
      "[[467 103  73]\n",
      " [138 486  21]\n",
      " [ 12   8 645]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.76      0.73      0.74       643\n",
      "not depression       0.81      0.75      0.78       645\n",
      "        severe       0.87      0.97      0.92       665\n",
      "\n",
      "      accuracy                           0.82      1953\n",
      "     macro avg       0.81      0.82      0.81      1953\n",
      "  weighted avg       0.82      0.82      0.82      1953\n",
      "\n",
      "Precision : 0.8182283666154634\n",
      "Recall : 0.8182283666154634\n",
      "F1-score : 0.8182283666154634\n"
     ]
    }
   ],
   "source": [
    "mdl = MultinomialNB(alpha=1.0,fit_prior=True)\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Multinomial Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd36b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = SVC()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Support Vector Classifer: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f48311",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = DecisionTreeClassifier()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Decision Tree: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = KNeighborsClassifier(n_neighbors=10 , metric= 'minkowski' , p = 4)\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic K Nearest Neighbor: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef0c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('preprocessed_dev_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad4c93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pid</th>\n",
       "      <th>text data</th>\n",
       "      <th>Class labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_pid_1</td>\n",
       "      <td>im scared lie every day say ill make think mig...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_pid_2</td>\n",
       "      <td>new wanted vent finally realized im kind bad m...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_pid_3</td>\n",
       "      <td>im sad kinda always issue wouldnt say bad peer...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_pid_4</td>\n",
       "      <td>lonely alone immediately family members dead d...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_pid_5</td>\n",
       "      <td>year trash dont know im posting dont even know...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>dev_pid_2514</td>\n",
       "      <td>anyone feared theyll kill loved ones sleep uni...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>dev_pid_2829</td>\n",
       "      <td>finally got fulltime job feel even worse maybe...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>dev_pid_2260</td>\n",
       "      <td>deal boredomnothing satisfying anymore days ta...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>dev_pid_2653</td>\n",
       "      <td>got bed showered morning removed</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>dev_pid_2460</td>\n",
       "      <td>depressed suicidal 2018 start 2020 ive woken d...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6507 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pid                                          text data  \\\n",
       "0        dev_pid_1  im scared lie every day say ill make think mig...   \n",
       "1        dev_pid_2  new wanted vent finally realized im kind bad m...   \n",
       "2        dev_pid_3  im sad kinda always issue wouldnt say bad peer...   \n",
       "3        dev_pid_4  lonely alone immediately family members dead d...   \n",
       "4        dev_pid_5  year trash dont know im posting dont even know...   \n",
       "...            ...                                                ...   \n",
       "6502  dev_pid_2514  anyone feared theyll kill loved ones sleep uni...   \n",
       "6503  dev_pid_2829  finally got fulltime job feel even worse maybe...   \n",
       "6504  dev_pid_2260  deal boredomnothing satisfying anymore days ta...   \n",
       "6505  dev_pid_2653                   got bed showered morning removed   \n",
       "6506  dev_pid_2460  depressed suicidal 2018 start 2020 ive woken d...   \n",
       "\n",
       "        Class labels  \n",
       "0           moderate  \n",
       "1           moderate  \n",
       "2           moderate  \n",
       "3           moderate  \n",
       "4           moderate  \n",
       "...              ...  \n",
       "6502  not depression  \n",
       "6503  not depression  \n",
       "6504  not depression  \n",
       "6505  not depression  \n",
       "6506  not depression  \n",
       "\n",
       "[6507 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4b0d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pid</th>\n",
       "      <th>text data</th>\n",
       "      <th>Class labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_pid_1</td>\n",
       "      <td>im scared lie every day say ill make think mig...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_pid_2</td>\n",
       "      <td>new wanted vent finally realized im kind bad m...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_pid_3</td>\n",
       "      <td>im sad kinda always issue wouldnt say bad peer...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_pid_4</td>\n",
       "      <td>lonely alone immediately family members dead d...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_pid_5</td>\n",
       "      <td>year trash dont know im posting dont even know...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pid                                          text data Class labels\n",
       "0  dev_pid_1  im scared lie every day say ill make think mig...     moderate\n",
       "1  dev_pid_2  new wanted vent finally realized im kind bad m...     moderate\n",
       "2  dev_pid_3  im sad kinda always issue wouldnt say bad peer...     moderate\n",
       "3  dev_pid_4  lonely alone immediately family members dead d...     moderate\n",
       "4  dev_pid_5  year trash dont know im posting dont even know...     moderate"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74db56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "x = data['text data']\n",
    "y = data['Class labels']\n",
    "x = np.array(data.iloc[:,0].values)\n",
    "y = np.array(data['Class labels'].values)\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(data['text data']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c6e5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51586a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c294c646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2694014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not depression', 'severe', 'moderate', ..., 'moderate', 'severe',\n",
       "       'severe'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10197f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['moderate', 'severe', 'moderate', ..., 'severe', 'not depression',\n",
       "       'not depression'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88402296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76ee7ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VASANTHARAN 21ADR056\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\VASANTHARAN 21ADR056\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\VASANTHARAN 21ADR056\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Logistic Regression: % 86.33\n",
      "Confusion Matrix\n",
      "[[426 175  42]\n",
      " [ 48 595   2]\n",
      " [  0   0 665]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.90      0.66      0.76       643\n",
      "not depression       0.77      0.92      0.84       645\n",
      "        severe       0.94      1.00      0.97       665\n",
      "\n",
      "      accuracy                           0.86      1953\n",
      "     macro avg       0.87      0.86      0.86      1953\n",
      "  weighted avg       0.87      0.86      0.86      1953\n",
      "\n",
      "Precision : 0.8632872503840245\n",
      "Recall : 0.8632872503840245\n",
      "F1-score : 0.8632872503840245\n"
     ]
    }
   ],
   "source": [
    "mdl = LogisticRegression()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Logistic Regression: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142b6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Gaussian Naive Bayes: % 72.3\n",
      "Confusion Matrix\n",
      "[[272 133 238]\n",
      " [ 44 475 126]\n",
      " [  0   0 665]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.86      0.42      0.57       643\n",
      "not depression       0.78      0.74      0.76       645\n",
      "        severe       0.65      1.00      0.79       665\n",
      "\n",
      "      accuracy                           0.72      1953\n",
      "     macro avg       0.76      0.72      0.70      1953\n",
      "  weighted avg       0.76      0.72      0.70      1953\n",
      "\n",
      "Precision : 0.7229902713773682\n",
      "Recall : 0.7229902713773682\n",
      "F1-score : 0.722990271377368\n"
     ]
    }
   ],
   "source": [
    "mdl = GaussianNB()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Gaussian Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf46ac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Random Forest: % 92.99\n",
      "Confusion Matrix\n",
      "[[577  64   2]\n",
      " [ 71 574   0]\n",
      " [  0   0 665]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.89      0.90      0.89       643\n",
      "not depression       0.90      0.89      0.89       645\n",
      "        severe       1.00      1.00      1.00       665\n",
      "\n",
      "      accuracy                           0.93      1953\n",
      "     macro avg       0.93      0.93      0.93      1953\n",
      "  weighted avg       0.93      0.93      0.93      1953\n",
      "\n",
      "Precision : 0.9298515104966718\n",
      "Recall : 0.9298515104966718\n",
      "F1-score : 0.9298515104966718\n"
     ]
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0)\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Random Forest: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b889d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score of Basic Multinomial Naive Bayes: % 81.82\n",
      "Confusion Matrix\n",
      "[[467 103  73]\n",
      " [138 486  21]\n",
      " [ 12   8 645]]\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      moderate       0.76      0.73      0.74       643\n",
      "not depression       0.81      0.75      0.78       645\n",
      "        severe       0.87      0.97      0.92       665\n",
      "\n",
      "      accuracy                           0.82      1953\n",
      "     macro avg       0.81      0.82      0.81      1953\n",
      "  weighted avg       0.82      0.82      0.82      1953\n",
      "\n",
      "Precision : 0.8182283666154634\n",
      "Recall : 0.8182283666154634\n",
      "F1-score : 0.8182283666154634\n"
     ]
    }
   ],
   "source": [
    "mdl = MultinomialNB(alpha=1.0,fit_prior=True)\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Multinomial Naive Bayes: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6dcaf8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m oneVsRest \u001b[38;5;241m=\u001b[39m OneVsRestClassifier(mdl)\n\u001b[0;32m      3\u001b[0m oneVsRest\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43moneVsRest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_score(y_test, y_pred) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      6\u001b[0m precision, recall, f1score, support \u001b[38;5;241m=\u001b[39m score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:443\u001b[0m, in \u001b[0;36mOneVsRestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    441\u001b[0m argmaxima \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_samples, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_):\n\u001b[1;32m--> 443\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43m_predict_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m     np\u001b[38;5;241m.\u001b[39mmaximum(maxima, pred, out\u001b[38;5;241m=\u001b[39mmaxima)\n\u001b[0;32m    445\u001b[0m     argmaxima[maxima \u001b[38;5;241m==\u001b[39m pred] \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:100\u001b[0m, in \u001b[0;36m_predict_binary\u001b[1;34m(estimator, X)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# probabilities of the positive class\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     score \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:756\u001b[0m, in \u001b[0;36mBaseSVC.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate the decision function for the samples in X.\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \n\u001b[0;32m    732\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03m    transformation of ovo decision function.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_shape \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ovr_decision_function(dec \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39mdec, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:520\u001b[0m, in \u001b[0;36mBaseLibSVM._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    518\u001b[0m     dec_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_decision_function(X)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     dec_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dense_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;66;03m# In binary case, we need to flip the sign of coef, intercept and\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# decision function.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:536\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(kernel):\n\u001b[0;32m    534\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLIBSVM_IMPL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mdl = SVC()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Support Vector Classifer: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada56541",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = DecisionTreeClassifier()\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic Decision Tree: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = KNeighborsClassifier(n_neighbors=10 , metric= 'minkowski' , p = 4)\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
    "print(f'Test Accuracy Score of Basic K Nearest Neighbor: % {accuracy}')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall : {recall}')\n",
    "print(f'F1-score : {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad408d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
